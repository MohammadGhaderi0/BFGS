\documentclass{article}
\usepackage{amsmath} % برای نمادها و معادلات ریاضی
\usepackage{graphicx} % برای وارد کردن تصاویر
\usepackage{xepersian} % برای پشتیبانی از زبان فارسی
\settextfont{Arial} % تنظیم فونت فارسی

\title{BFGS}
\author{محمد قادری، آرمین جودت، امیرحسین امین نگارشی}
\date{می ۲۰۲۴}

\begin{document}

\maketitle

\section{مقدمه}

در حوزه بهینه‌ سازی، روش‌های مختلفی برای یافتن کمینه یک تابع توسعه یافته‌اند. از بین این روش‌ها، روش‌های گرادیان کاهشی و روش نیوتن دو روش شناخته شده هستند.

\section{گرادیان کاهشی}

گرادیان کاهشی یک الگوریتم تکراری بهینه‌ سازی است که برای یافتن کمینه یک تابع استفاده می‌شود. این روش به دلیل سادگی و کارایی بالا، به ویژه در کاربردهای یادگیری ماشین و یادگیری عمیق، به طور گسترده استفاده می‌شود. طریقه  به‌روزرسانی برای نزول گرادیان به صورت زیر است:
\begin{equation}
x_{k+1} = x_k - \alpha \nabla f(x_k)
\end{equation}
 

\section{روش نیوتن}

روش نیوتن از اطلاعات مرتبه دوم برای تسریع همگرایی استفاده می‌کند. نحوه به‌ روزرسانی برای روش نیوتن به صورت زیر است:
\begin{equation}
x_{k+1} = x_k - H_f(x_k)^{-1} \nabla f(x_k)
\end{equation}
که در آن \( H_f(x_k) \) ماتریس هسیان مشتقات دوم در \( x_k \) است.

در حالی که روش نیوتن سریع‌تر از نزول گرادیان همگرا می‌شود، دارای برخی معایب است:
\begin{itemize}
    \item محاسبه ماتریس هسیان می‌تواند محاسباتی گران باشد.
    \item معکوس کردن ماتریس هسیان حتی بیشتر محاسباتی است.
    \item روش نیوتن نیازمند است که هسیان مثبت معین باشد، که همیشه اینگونه نیست.
\end{itemize}

\section{روش‌های شبه نیوتنی}

روش‌های شبه نیوتنی تلاش می‌کنند تا همگرایی سریع روش نیوتن را حفظ کنند و در عین حال بار محاسباتی مرتبط با محاسبه و معکوس کردن ماتریس هسیان را کاهش دهند. این روش‌ها تقریب ماتریس هسیان را که به صورت تکراری به‌روز می‌شود، می‌سازند.

\section{الگوریتم BFGS}

یکی از محبوب‌ترین روش‌های شبه نیوتنی، الگوریتم برویدن- فلچر- گلدفارب- شانو (BFGS) است. الگوریتم BFGS تقریب ماتریس هسیان \( B_k \) را در هر تکرار با استفاده از فرمول زیر به‌روز می‌کند:
\begin{equation}
B_{k+1} = B_k + \frac{y_k y_k^T}{y_k^T s_k} - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k}
\end{equation}
که در آن \( s_k = x_{k+1} - x_k \) و \( y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \) است.

\subsection{مراحل الگوریتم}

الگوریتم BFGS به شرح زیر پیش می‌رود:

1. انتخاب حدس اولیه \( x_0 \)

2. انتخاب \( B_0 \)، حدس اولیه هسیان، مثلاً \( B_0 = I \)

3. برای \( k = 0, 1, 2, \ldots \) انجام دهید:

\hspace{0.5cm} 1. بدست آوردن \( p_k \)  با حل \( B_k p_k = -\nabla f (x_k) \)

\hspace{0.5cm} 2. جستجوی خطی برای یافتن \( \alpha_k \) که \( f(x_k + \alpha_k p_k) \) را به طور کافی کاهش دهد.

\hspace{0.5cm} 3. \( s_k = \alpha_k p_k \)

\hspace{0.5cm} 4. \( x_{k+1} = x_k + s_k \)

\hspace{0.5cm} 5. \( y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \)

\hspace{0.5cm} 6. \( B_{k+1} = B_k + \Delta B_k \)

4. پایان حلقه

که در آن
\begin{equation}
\Delta B_k \equiv \frac{y_k y_k^T}{y_k^T s_k} - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k}
\end{equation}

\subsection{به‌روزرسانی ماتریس هسیان معکوس در الگوریتم BFGS}

یک روش جایگزین در چارچوب BFGS شامل به‌روزرسانی ماتریس هسیان معکوس به طور مستقیم است. این روش ماتریس هسیان معکوس \( H_k \) را در هر تکرار با استفاده از مراحل زیر به‌روزرسانی می‌کند:

1. انتخاب حدس اولیه \( x_0 \)

2. انتخاب \( H_0 \)، حدس اولیه هسیان معکوس، مثلاً \( H_0 = I \)

3. برای \( k = 0, 1, 2, \ldots \) انجام دهید:

\hspace{0.5cm} 1. محاسبه جهت جستجو: \( p_k = -H_k \nabla f (x_k) \)

\hspace{0.5cm} 2. انجام جستجوی خطی برای تعیین اندازه گام \( \alpha_k \)

\hspace{0.5cm} 3. تنظیم \( s_k = \alpha_k p_k \)

\hspace{0.5cm} 4. \( x_{k+1} = x_k + s_k \)

\hspace{0.5cm} 5. \( y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \)

\hspace{0.5cm} 6. به‌روزرسانی ماتریس هسیان معکوس \( H_k \):
\begin{equation}
H_{k+1} = (I - \rho_k s_k^T) H_k (I - y_k s_k^T) + \rho_k s_k^T
\end{equation}

4. پایان جلقه

که در آن
\begin{equation}
\rho_k = \frac{1}{y_k^T s_k}
\end{equation}

\section{شرایط BFGS}

یکی از شرایطی که همه روش‌های شبه نیوتنی باید داشته باشند، این است که تقریب هسیان \( B \) باید شرط شبه نیوتنی (یا معادله سکانت) را برآورده کند:
\begin{equation}
B_{k+1} \Delta x_k = y_k
\end{equation}
که در آن

\hspace{1.5cm}\( \Delta x_k = x_{k+1} - x_k \) 

\hspace{0.3cm}\( y_k = \nabla f(x_{k+1}) - \nabla f(x_k) \)
\vspace{0.3cm}

علاوه بر این، تقریب هسیان \( B \) باید متقارن و معین مثبت باقی بماند. برای اطمینان از پایداری ، \( B_{k+1} \) باید در هر به‌ روزرسانی به اندازه کافی نزدیک به \( B_k \) باشد. این نزدیکی اغلب با استفاده از یک نرم ماتریسی اندازه‌گیری می‌شود:
\begin{align}
\min &\| B_{k+1} - B_k \| \\
\text{s.t} \quad &B_{k+1}^T = B_{k+1} \\
&B_{k+1} \Delta x_k = y_k
\end{align}

در عمل، اغلب معکوس هسیان \( B^{-1} \) است که مستقیماً محاسبه می‌شود. این منجر به یک مسئله بهینه‌سازی مشابه می‌شود:
\begin{align}
\min &\| {B^{-1}}_{k+1} - {B^{-1}}_k \| \\
\text{s.t} \quad &{B^{-1}}_{k+1}^T = {B^{-1}}_{k+1} \\
&{B^{-1}}_{k+1} y_k = \Delta x_k
\end{align}

انتخاب‌های مختلفی از نرم‌های ماتریسی منجر به روش‌های شبه نیوتنی مختلفی می‌شود. در روش BFGS، نرم به صورت نرم فروبنیوس انتخاب می‌شود. مسئله به‌روزرسانی تقریب هسیان در هر تکرار معادل اضافه کردن دو ماتریس متقارن،رنک یک \( U \) و \( V \) است:
\begin{equation}
B_{k+1} = B_k + U + V
\end{equation}

برای برآورده کردن شرایط مذکور، ماتریس‌های \( U \) و \( V \) به گونه‌ای انتخاب می‌شوند که به فرم \( U = a uu^T \) و \( V = b vv^T \) باشند، جایی که \( u \) و \( v \) بردارهای غیرصفر مستقل خطی هستند و \( a \) و \( b \) ثابت‌ها:
\begin{equation}
B_{k+1} = B_k + auu^T + bvv^T
\end{equation}

برای اطمینان از تقارن و معین مثبت بودن، ماتریس‌های \( U \) و \( V \) در به‌روزرسانی BFGS به گونه‌ای انتخاب می‌شوند که:
\begin{equation}
u = y_k \quad \text{و} \quad v = B_k \Delta x_k
\end{equation}
با ثابت‌ها:
\begin{equation}
a = \frac{1}{y_k^T \Delta x_k} \quad \text{و} \quad b = -\frac{1}{\Delta x_k^T B_k \Delta x_k}
\end{equation}

این منجر به فرمول نهایی به‌روزرسانی BFGS می‌شود:
\begin{equation}
B_{k+1} = B_k + \frac{y_k y_k^T}{y_k^T s_k} - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k}
\end{equation}

روش BFGS تقریب معین مثبت از هسیان را حفظ می‌کند، اطمینان حاصل می‌کند که جهت جستجو یک جهت نزولی باقی می‌ماند. این منجر به همگرایی سریع‌تر نسبت به گرادیان کاهشی  می‌شود.

\end{document}
